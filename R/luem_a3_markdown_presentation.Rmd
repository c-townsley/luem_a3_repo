---
title: "Estimating a Flood Inundation Probability Map"
subtitle: "CPLN 675 Assignment3"
author: "Riddhi Batra & Charlie Townsley"
date: "`r Sys.Date()`"
output:   
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
    code_folding: hide
    df_print: paged
    theme: flatly
    highlight: tango
---



# 1. Introduction


The purpose of this project is to use existing flood inundation and environmental data from one city to build a predictive model that estimates flooding in a comparison city with similar characteristics. 


## Project Structure

This project follows the workflow below, which the following sections describe in detail:

1. Setup
     + Gather open data from Calgary and Denver
     + Process open data in ArcGIS to get our features of interest.


2. Create Fishnets and Wrangle data
     + Create a fishnet shapefile in R for each city
     + Use the Zonal Statistics as Table tool in ArcGIS to transform raster features to fishnet cell-level information
     + Join zonal statistics tables with fishnet shapefiles in R
     + Explore data in R


3. Run Logistic Regressions
     + Train model on Calgary Data
     + Refine model
     + Validate model
  

4. Interpretation

5. Map Predictions

6. Conclude with Closing Thoughts


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

#knitr::opts_knit$set(root.dir = "C:/Users/ctown/OneDrive - PennO365/Classes/Classes_Sem4_2023Spring/CPLN 675_Land Modeling/Assignments/LUEM_Assignment3_FloodInundationProbability/Data") #Charlie's directory

knitr::opts_knit$set(root.dir = "C:/Users/rids2/PennO365/Townsley, Charlie - LUEM_Assignment3_FloodInundationProbability/Data") #Riddhi's Directory

rm(list=ls())

options(scipen = 999)

```

```{r libraries, echo=FALSE}
library(tidyverse)
library(sf)
library(raster)
library(data.table)
library(ggcorrplot)
library(caret)
library(pscl)
library(plotROC)
library(pROC)
library(kableExtra)
library(tigris)
library(viridis)
library(RColorBrewer)
library(tinytex)
```

```{r themes, results = "hide"}

mapTheme <- theme(plot.title =element_text(size=12),
                  plot.subtitle = element_text(size=8),
                  plot.caption = element_text(size = 6),
                  axis.line=element_blank(),
                  axis.text.x=element_blank(),
                  axis.text.y=element_blank(),
                  axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank(),
                  panel.background=element_blank(),
                  panel.border=element_blank(),
                  panel.grid.major=element_line(colour = 'transparent'),
                  panel.grid.minor=element_blank(),
                  legend.direction = "vertical", 
                  legend.position = "right",
                  plot.margin = margin(1, 1, 1, 1, 'cm'),
                  legend.key.height = unit(1, "cm"), legend.key.width = unit(0.2, "cm"))

plotTheme <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.75),
  axis.ticks=element_blank())

#color nerds

blues <- c("#CEEBF0", "#A2D3D8", "#73B8BF", "#51A6AE", "#468D94", "#34696E")

greens <- c("#D8E5CE", "#C1D4B5", "#A9BF99", "#92AF7E", "#81996F", "#668053")

yellows <- c("#F9E2B2", "#EDC876", "#EDBA46", "#EDB025", "#AC832D", "#6E5321")

greys <- c("#ECEBF1", "#D3D3D9", "#B0B0B3", "#9C9C9E", "#7F7F80", "#656666")

neutrals <- c("#FDF4E9", "#FFEFDE", "#F6D7B2", "#D6B28B", "#A58565")

```

```{r load_data, results = "hide"}
denver_boundary <-read_sf("Denver/Processed/LUEM_Asgn3_Denver/NewData/denver_bound/denver_bound.shp")

calgary_boundary <- read_sf("Calgary/Raw/CALGIS_CITYBOUND_LIMIT/CALGIS_CITYBOUND_LIMIT.shp")
```


# 2. Fishnets and Data Wrangling


## 2.1 Create Fishnets

```{r create_fishnets_calgary, results = "hide"}

calgary_fishnet <- st_make_grid(calgary_boundary,
                        cellsize = 402.336,
                        square = FALSE) %>% 
  .[calgary_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = calgary_fishnet,
          fill = "lightgrey")+
  geom_sf(data = calgary_boundary, 
          color = "#6E5321", fill = "transparent") +
  mapTheme

#st_write(calgary_fishnet, "Calgary/Processed/calgary_fishnet/calgary_fishnet.shp", geometry = TRUE)

```


Create a fishnet for Denver to do processing in ArcGIS.

```{r create_fishnets_denver, results = "hide"}

denver_fishnet <- st_make_grid(denver_boundary,
                        cellsize = 1320,
                        square = FALSE) %>% 
  .[denver_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = denver_fishnet,
          color="darkgrey", fill = "lightgrey") +
  geom_sf(data = denver_boundary, 
          color = "#6E5321", fill = "transparent") +
  mapTheme

#st_write(denver_fishnet, "Denver/Processed/R exports/denver_fishnet/denver_fishnet.shp", geometry = TRUE)
```


## 2.2 Feature Engineering: Arc to R

After creating fishnets for Calgary and Denver in R, we exported them as shapefiles for processing in ArcGIS. where we created tables of zonal statistics from relevant raster data.

```{r join engineered features to calg fishnet, results = "hide"}

#load in cleaned fishnet with partial cells removed
calgary_fishnet <-  read_sf("Calgary/Processed/calgary_fishnet_nozeros/calgary_fishnet_nozeros.shp")

#load in engineered features for calgary and process
calg_inund <- read_csv("Calgary/Processed/zonalstats_tables/calg_inundation_sum.csv") %>%
  rename(inund_sum = SUM) %>% 
  dplyr::select(uniqueID, inund_sum) %>% 
  mutate(inund_sum = ifelse(inund_sum >= 16, 1, 0)) #turn inundation sum values into binary (threshold = 16)

calg_pervious <- read.csv("Calgary/Processed/zonalstats_tables/calg_pervious_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(pervious_mean = MEAN)

calg_elevation <- read.csv("Calgary/Processed/zonalstats_tables/calg_elevation_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(elevation_mean = MEAN)

calg_flowac <- read.csv("Calgary/Processed/zonalstats_tables/calg_flowac_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(flowac_mean = MEAN)

calg_streamdist <- read.csv("Calgary/Processed/zonalstats_tables/calg_dist2stream_min.csv") %>% 
    dplyr::select(uniqueID, MIN) %>% 
  rename(streamdist_min = MIN)

calg_dat <- calgary_fishnet %>%
  mutate(uniqueID = as.integer(uniqueID)) %>% 
  left_join(calg_inund, by = "uniqueID") %>% 
  left_join(calg_pervious, by = "uniqueID") %>%
  left_join(calg_elevation, by = "uniqueID") %>% 
  left_join(calg_flowac, by = "uniqueID") %>% 
  left_join(calg_streamdist, by = "uniqueID") %>% 
  mutate(flowac_mean_log = log(flowac_mean),
         streamdist_min_log = log(streamdist_min)) %>% 
  na.omit() %>% 
    dplyr::mutate(streamdist_min_log = if_else(streamdist_min_log <0, 0, streamdist_min_log),
         flowac_mean_log = if_else(flowac_mean_log <0, 0, flowac_mean_log)) %>% 
  na.omit()
  
```

```{r get_variables_denver, results = "hide"}

denv_pervious <- read.csv ("Denver/Processed/zonalstats_tables/denv_pervious_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(pervious_mean = MEAN)

denv_elevation <- read.csv("Denver/Processed/zonalstats_tables/denver_elevation_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(elevation_mean = MEAN)


denv_flowac <- read.csv("Denver/Processed/zonalstats_tables/denv_flowac_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(flowac_mean = MEAN)


denv_streamdist <- read.csv("Denver/Processed/zonalstats_tables/denv_dist2stream_min.csv") %>% 
    dplyr::select(uniqueID, MIN) %>% 
  rename(streamdist_min = MIN)


denver_dat <- denver_fishnet %>%
  mutate(uniqueID = as.integer(uniqueID)) %>% 
  left_join(denv_pervious, by = 'uniqueID') %>%
  left_join(denv_elevation, by = 'uniqueID') %>% 
  left_join(denv_flowac, by = 'uniqueID') %>% 
  left_join(denv_streamdist, by = 'uniqueID') %>%
  mutate(flowac_mean = flowac_mean*0.3048,
         streamdist_min = streamdist_min*0.3048) %>% 
    mutate(flowac_mean_log = log(flowac_mean),
         streamdist_min_log = log(streamdist_min)) %>% 
  na.omit() %>% 
    dplyr::mutate(streamdist_min_log = if_else(streamdist_min_log <0, 0, streamdist_min_log),
         flowac_mean_log = if_else(flowac_mean_log <0, 0, flowac_mean_log))

```


### Calgary

Below are the features we created for Calgary:

* Flood inundation
* Pervious and impervious landcover
* Elevation
* Flow accumulation
* Distance to river


```{r calgary inundation map}
calg_dat <- calg_dat %>%
  st_transform(crs = 3776)

ggplot() +
  geom_sf(data=calg_dat, aes(fill=as.factor(inund_sum)), alpha = 0.8, color = NA) +
  scale_fill_manual(values = c("#CEEBF0", "#51A6AE"),
                    labels = c("Not Inundated", "Inundated"),
                    name = "Observed\nFlooding") +
  labs(title="Flood Inundation in Calgary",
       subtitle="Based on observed flooding in Calgary",
        caption = "Source: CPLN 675") +
  mapTheme
```

```{r calgary stream dist map}
              
ggplot() +
  geom_sf(data=calg_dat, aes(fill=factor(ntile(streamdist_min, 4))), 
            colour=NA) +
  scale_fill_manual(values = yellows,
                    labels= as.character(round(quantile(calg_dat$streamdist_min,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T))),
                    name = "Distance\n(Quantile Breaks\nin Meters)") +
  labs(title="Distance from Rivers in Calgary",
      subtitle="Based on Calgary Hydrology Data",
      caption = "Source: data.calgary.ca") +
  mapTheme                    
                    
```

```{r calgary fac map}

ggplot() +
  geom_sf(data=calg_dat, aes(fill=factor(ntile(flowac_mean,4))), 
            colour=NA) +
  scale_fill_manual(values = blues,
                    labels= as.character(round(quantile(calg_dat$flowac_mean,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T))),
                    name = "Mean Flow\nAccumulation\n(Quantile Breaks)") +
  labs(title="Precipitation Flow Accumulation in Calgary",
       subtitle="Based on Calgary Elevation Data",
        caption = "Source: 18M DEM, CPLN 675") +
  mapTheme

```

```{r calgary pervious surface map}

ggplot() +
  geom_sf(data=calg_dat, aes(fill=factor(ntile(pervious_mean,4))), 
            colour=NA) +
  scale_fill_manual(values = greens,
                    labels= as.character(round(quantile(calg_dat$pervious_mean,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T), 2)),
                    name = "Pervious\nSurface\n(Quantile\nBreaks)") +
  labs(title="Pervious Surface in Calgary",
       subtitle="Based on Calgary Land Cover Data",
        caption = "Source: data.calgary.ca") +
  mapTheme

```

```{r calgary elevation map}

ggplot() +
  geom_sf(data=calg_dat, aes(fill=factor(ntile(elevation_mean,4))), 
            colour=NA) +
  scale_fill_manual(values = neutrals,
                    labels= as.character(round(quantile(calg_dat$elevation_mean,
                                                         c(0.2,.4,.6,.8),
                                                         na.rm=T), 2)),
                    name = "Mean Elevation\n(Quantile Breaks\nCategorical)") +
  labs(title="Elevation in Calgary",
        caption = "Source: CPLN 675") +
    mapTheme


```

### Denver

We performed the exact same operations for the Denver features, excluding inundation which we're setting out to predict.

```{r mapping denver }
denver_dat <- denver_dat %>%
  st_transform(crs = 2232)
```


```{r denver stream dist map}

ggplot() +
  geom_sf(data=denver_dat, aes(fill=factor(ntile(streamdist_min,4))), 
            colour=NA) +
  scale_fill_manual(values = yellows,
                    labels= as.character(round(quantile(denver_dat$streamdist_min,                                                    c(0.2,.4,.6,.8),
                                        na.rm=T), 2)),
     name = "Distance\n(Quantile Breaks\n in Metres)") +
  labs(title="Distance from Rivers in Denver",
       subtitle="Based on Denver Hydrology Data",
        caption = "Source: Denver Open Data Catalog") +
  mapTheme

```


```{r denver fac map}

ggplot() +
  geom_sf(data=denver_dat, aes(fill=factor(ntile(flowac_mean,4))), 
            colour=NA) +
  scale_fill_manual(values = blues,
                    labels= as.character(round(quantile(denver_dat$flowac_mean,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T))),
                    name = "Mean Flow\nAccumulation\n(Quantile Breaks)") +
  labs(title="Precipitation Flow Accumulation in Denver",
       subtitle="Based on Denver Elevation Data",
        caption = "Source: webgis.com") +
  mapTheme

```


```{r denver pervious surface map}

ggplot() +
  geom_sf(data=denver_dat, aes(fill=factor(ntile(pervious_mean,4))), 
            colour=NA) +
  scale_fill_manual(values = greens,
                    labels= as.character(round(quantile(denver_dat$pervious_mean,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T), 2)),
                    name = "Permeable\nSurface\n(Quantile\nBreaks)") +
  labs(title="Permeable Surface in Denver",
       subtitle="Based on Denver Land Cover Data",
        caption = "Source: Denver Regional Council of Governments Regional Data Catalog") +
  mapTheme

```
```{r denver elevation map}

ggplot() +
  geom_sf(data=denver_dat, aes(fill=factor(ntile(elevation_mean,4))), 
            colour=NA) +
  scale_fill_manual(values = neutrals,
                    labels= as.character(round(quantile(denver_dat$elevation_mean,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T))),
                    name = "Mean Elevation\n(Quantile Breaks\nCategorical)") +
  labs(title="Elevation in Denver",
        caption = "Source: webgis.com") +
  mapTheme

```


## 2.4 What is our Data Telling Us?


We had to log adjust our Flow Accumulation and Distance to Stream variables to compensate the wide range of outliers in the data set. 

```{r wide_2_long}
calg_PlotVariables <- calg_dat %>% 
  as.data.frame() %>%
    dplyr::select(inund_sum, pervious_mean, elevation_mean, flowac_mean_log, streamdist_min_log) %>% 
    pivot_longer(cols = -inund_sum)
```


The violin plots below shows how each variable is spread across 0/1 values of inundation.


``` {r data spread, results = "hide"}

#violin plots
#change code for for calgary_dat
##use boxplots with scatter points to visualize the spread of data?

ggplot(calg_PlotVariables) + 
     geom_violin(aes(x = as.factor(inund_sum), 
                  y = value, fill = as.factor(inund_sum))) + 
     facet_wrap(~name, scales = "free_y") +
     labs(x="Inundated", y="Value") + 
     scale_fill_manual(values = c("#CEEBF0", "#51A6AE"),
     labels = c("Not Inundated","Inundated"), name = "") +
     labs(x="Inundated", y="Value") + 
  plotTheme

##facet_wrap - one ggplot recipe for each variable
###use scales = free or free_y to plot values that are comparatively lower or higher
```


**How many fishnet cells in Calgary are inundated?**


``` {r fishnet cell calcs, results = "hide"}

calg_inund_fishnet <- calg_dat %>% 
  filter(inund_sum == 1)

no_fishnets <-(509/5373)*100


```


# 3. Logistic Regressions

## 3.1 Test, Train, Correlate, Regress: Model 1

Our first binomial regression model inputs the Calgary training set with the dependent variable set to "Inundation", and four independent variables.

```{r training_set, results = "hide"}

set.seed(3456)

trainIndex <- createDataPartition(calg_dat$elevation_mean, p = .70,
                                  list = FALSE,
                                  times = 1) 

inundTrain <- calg_dat[ trainIndex,] %>% 
  dplyr::select(-flowac_mean, -streamdist_min)

inundTest  <- calg_dat[-trainIndex,]%>% 
  dplyr::select(-flowac_mean, -streamdist_min)

##the sets are randomly generated
##p=0.70 indicates the 70/30 partition
```

## Correlation Test

``` {r correlation matrix, results = "hide"}

corr <- calg_dat %>%
  as.data.frame() %>%
  dplyr::select(inund_sum, pervious_mean, elevation_mean, flowac_mean_log, streamdist_min_log) %>% 
  rename("Distance to Stream (log)" = streamdist_min_log,
         "Flow Accumulation (log)" = flowac_mean_log,
         "Elevation" = elevation_mean,
         "Land Porosity" = pervious_mean,
         "Inundation (observed)" = inund_sum)


calg_matrix = cor(corr)

ggcorrplot(calg_matrix, method="square", colors = c("#73BBBF", "#FDF4E9", "#92AF7E"),
           tl.cex=7)

```

A logistic regression on the first model displays the following results:

* The p-values indicate a high level of statistical significance.

* The Aikake Information Criterion (AIC) is **1259.8**.


```{r firstModel, warning=FALSE}
inundModel <- glm(inund_sum ~ ., 
                    family="binomial"(link="logit"), data = inundTrain %>%
                                                            as.data.frame() %>%
                                                            dplyr::select(-geometry, -uniqueID))
summary(inundModel)
```

The exponentiated coefficients of the first model exhibit the following relationships between the dependent and independent variables:

* All else equal, a unit increase in Land Porosity _reduces_ the chances of inundation by 30.56%
* All else equal, a unit increase in Elevation _reduces_ the chances of flood inundation by 47%
* All else equal, a unit change in Flow Accumulation _increases_ the odds of flood inundation by 13.9%
* All else equal, a unit increase in Distance to Stream _reduces_ the odds of flood inundation by 41.1%


``` {r firstModel coefficients, warning=FALSE, results="hide"}

## % change in Y for unit change in X = [(exponent (coefficient of X) - 1)] * 100
## - or + sign indicates associated increase or decrease

inundModel$coefficients

inundModel_vars <- c("Land Porosity", "Elevation", "Flow Accumulation (log)", "Distance to Stream (log)")
inundModel_coeffs <- c(((exp(-0.3648453 ) - 1) * 100), ((exp(-0.6357177) - 1) * 100), ((exp(0.1009900) - 1) * 100), ((exp( -0.5288784) - 1) * 100))

inundModel_coefficients <- data.frame(inundModel_vars, inundModel_coeffs)

inundModel_coefficients %>% 
  kbl(caption = "Exponentiated Coefficients: Logistic Regression Model 1") %>% 
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")

```


## 3.2 Regress: Model 2 & 3


**Model 2: Does 'Land Porosity' matter?**

We eliminate Land Porosity, which did not exhibit statistical significance in our previous model.

* The resulting model shows that all independent variables are statistically significant.

* The AIC is very marginally lower than our first model, at **1259.2**.


```{r secondModel, warning=FALSE}

inundTrain_2 <- calg_dat[ trainIndex,] %>% 
  dplyr::select(-flowac_mean, -streamdist_min, -pervious_mean)

inundTest_2  <- calg_dat[-trainIndex,]%>% 
  dplyr::select(-flowac_mean, -streamdist_min, -pervious_mean)


inundModel_2 <- glm(inund_sum ~ ., 
                    family="binomial"(link="logit"), data = inundTrain_2 %>%
                                                            as.data.frame() %>%
                                                            dplyr::select(-geometry, -uniqueID))
summary(inundModel_2)

```

``` {r secondModel coefficients, warning=FALSE, results="hide"}

## % change in Y for unit change in X = [(exponent (coefficient of X) - 1)] * 100
## - or + sign indicates associated increase or decrease

inundModel_2$coefficients

inundModel2_vars <- c("Elevation", "Flow Accumulation (log)", "Distance to Stream (log)")
inundModel2_coeffs <- c(((exp(-0.6243868) - 1) * 100), ((exp(0.1009589) - 1) * 100), ((exp(-0.5192783) - 1) * 100))

inundModel2_coefficients <- data.frame(inundModel2_vars, inundModel2_coeffs)

inundModel2_coefficients %>% 
  kbl(caption = "Exponentiated Coefficients: Logistic Regression Model 2") %>% 
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")

```

**Model 3: What if we don't log-adjust our variables?**

* All variables except Land Porosity are statistically significant.

* The AIC is lower than the previous two models at **1185.2** (compared to 1253.8 and 1252.2 for models 1 and 2 respectively).

Does it mess with our coefficient interpretation?


```{r thirdModel, warning=FALSE}

inundTrain_3 <- calg_dat[ trainIndex,] %>% 
  dplyr::select(-flowac_mean_log, -streamdist_min_log)

inundTest_3  <- calg_dat[-trainIndex,]%>% 
  dplyr::select(-flowac_mean_log, -streamdist_min_log)


inundModel_3 <- glm(inund_sum ~ ., 
                    family="binomial"(link="logit"), data = inundTrain_3 %>%
                                                            as.data.frame() %>%
                                                            dplyr::select(-geometry, -uniqueID))
summary(inundModel_3)

```

The exponentiated coefficients non-log-adjusted Flow Accumulation and Distance to Streams is a _lot_ smaller -- funky, given that a variation in distance from a stream should logically affect the odds of inundation a lot more than 0.46%.


``` {r thirdModel coefficients, warning=FALSE, results="hide"}

## % change in Y for unit change in X = [(exponent (coefficient of X) - 1)] * 100
## - or + sign indicates associated increase or decrease

inundModel_3$coefficients

inundModel3_vars <- c("Land Porosity", "Elevation", "Flow Accumulation", "Distance to Stream")
inundModel3_coeffs <- c(((exp(0.0479009901) - 1) * 100), ((exp(-0.4802761173) - 1) * 100), ((exp(0.0001509916) - 1) * 100), ((exp(-0.0046012831) - 1) * 100))

inundModel3_coefficients <- data.frame(inundModel3_vars, inundModel3_coeffs)

inundModel3_coefficients %>% 
  kbl(caption = "Exponentiated Coefficients: Logistic Regression Model 2") %>% 
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")

```


## 3.3 Model Validation


**So, Is My House Going to Flood?**

Well, it depends on where you live.


The plots below illustrate a distribution of predicted probabilities, based on the training and test sets. 

```{r predict_first}
classProbs <- predict(inundModel, inundTest, type="response")


hist(classProbs)
  

##histogram is for the whole dataset
##represents the probability that a cell will be inundated (x-axis), vs number of cells with that probability (y-axis)
```

```{r plot_preds}
testProbs <- data.frame(obs = as.numeric(inundTest$inund_sum),
                        pred = classProbs)

ggplot(testProbs, aes(x = pred, fill=as.factor(obs))) + 
  geom_density() +
  facet_grid(obs ~ .) + 
  xlab("Probability") + 
  ylab("Frequency") +
  geom_vline(xintercept = .5) +
  scale_fill_manual(values = c("#CEEBF0", "#51A6AE"),
                      labels = c("Not Inundated","Inundated")) +
  labs(title = "Number of Fishnet Cells Associated with Flooding in Calgary")+
  plotTheme


```


# 4. Confusion, Indeed

## 4.1 Confusion Metrics

To test the model's prediction accuracy, we created a confusion matrix from which levels of error can be extrapolated.
If we assume a probability cutoff threshold of 50%, our confusion matrix gives us an accuracy of **0.909**.


Overall, the model's true positive rate, i.e., its _sensitivity_, is almost twice as much as the number of 1s falsely predicted as 0s. The model's true negative rate, is about 15 times greater than its false negative rate, indicating the model's _specificity_.

```{r confusion_matrix, warning=FALSE, results = "hide"}

testProbs$predClass  = ifelse(testProbs$pred > .5 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass), 
                       positive = "1")
```

We experimented with the threshold cutoff to check how the model would respond, and found minor differences in using a 75% and 25% cutoff.


```{r confusion_matrix_75_25, message = FALSE, warning = FALSE, results = "hide"}

testProbs$predClass75  = ifelse(testProbs$pred > .75 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass75), 
                       positive = "1")

testProbs$predClass25  = ifelse(testProbs$pred > .25 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass25), 
                       positive = "1")

```

## 4.2 ROC Curve


**Run, These Are No Geese!!**

The Receiver Operating Characteristic (ROC) curve, indicates a high rate of model accuracy, calculated at **94%**, 


```{r roc_curve, message = FALSE, warning = FALSE}

ggplot(testProbs, aes(d = obs, m = pred)) + 
  geom_roc(n.cuts = 50, labels = FALSE) + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') 

```

```{r auc, warning = FALSE}
auc(testProbs$obs, testProbs$pred)
```



## 4.3 Cross Validation


**It's Accurate but is it Generalizable?**


On average, the prediction accuracy across all 100 randomly generated test sets is **92%**.


```{r k_fold, warning = FALSE, message = FALSE, results = "hide"}

ctrl <- trainControl(method = "cv", 
                     number = 100, 
                     savePredictions = TRUE)

inundFit <- train(as.factor(inund_sum) ~ .,
               data = calg_dat %>% 
                 as.data.frame() %>%
                 dplyr::select(inund_sum, pervious_mean, elevation_mean, flowac_mean_log, streamdist_min_log), 
               method="glm", family="binomial",
               trControl = ctrl)

inundFit

#inundFit is our model trained to predict using the binomial logistic regression, or glm, method. 
```

Subsequently plotting a histogram of the accuracy for each fold points out a high level of generalizability.

```{r cv_hist, warning = FALSE, message = FALSE}

ggplot(as.data.frame(inundFit$resample), aes(Accuracy)) + 
  geom_histogram() +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Accuracy",
       y="Count")+
  plotTheme
```

# 5. Map Predictions

**The Moment We've Been Waiting For**

## 5.1 Predictions for Calgary

Looks like our predicted and observed values in Calgary are very close!

```{r predict_whole, warning = FALSE, message= FALSE}

calg_dat_log <- calg_dat %>% 
  dplyr::select(uniqueID, inund_sum, pervious_mean, elevation_mean, flowac_mean_log, streamdist_min_log, geometry)


allPredictions <- 
  predict(inundFit, calg_dat, type="prob")[,2]
  
calg_pred <- 
  cbind(calg_dat_log,allPredictions) %>%
  mutate(allPredictions = round(allPredictions * 100)) 
```


```{r predicted_map1, warning = FALSE, message = FALSE}
 ggplot() + 
    geom_sf(data=calg_pred, aes(fill=factor(ntile(allPredictions,4))), 
            colour=NA) +
    scale_fill_manual(values = blues,
                      labels=as.character(quantile(calg_pred$allPredictions,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Grouped in\nQuantile\nBreaks)") +
  mapTheme +
  labs(title="Predicted Probability of Flood Inundation in Calgary",
       subtitle = "Based on a Logistic Regression Model")
```

```{r predicted_map2, warning = FALSE, message = FALSE}
 ggplot() + 
  geom_sf(data=calg_pred, aes(fill=factor(ntile(allPredictions,4))), colour=NA) +
  scale_fill_manual(values = blues,
                    labels=as.character(quantile(calg_pred$allPredictions,
                                                 c(.2,.4,.6,.8),
                                                 na.rm=T)),
                    name="Predicted\nProbabilities(%)\n(Grouped in\nQuintile\nBreaks)") +
  geom_sf(data=calg_pred  %>% 
               filter(inund_sum == 1), 
               fill="#EDBA46", alpha=0.9, colour=NA) +
    geom_sf(data=calg_pred %>% 
              filter(inund_sum == 0), 
            fill="#F9E2B2", alpha=0.35,colour=NA) +  
  mapTheme +
  labs(title="Observed and Predicted Flood Inundation Areas",
       subtitle="Yellow marks areas with observed 'inundation', \nall other taken as 'not inundated' for the purpose of binary regression modeling")
```



**Errors on Map**

```{r error_map, warning = FALSE, message= FALSE}
calg_pred %>%
  mutate(confResult=case_when(allPredictions < 50 & inund_sum==0 ~ "True Negative",
                              allPredictions >= 50 & inund_sum==1 ~ "True Positive",
                              allPredictions < 50 & inund_sum==1 ~ "False Negative",
                              allPredictions >= 50 & inund_sum==0 ~ "False Positive")) %>%
  ggplot()+
  geom_sf(aes(fill = confResult), color = "transparent")+
  scale_fill_manual(values = c("#B0B0B3","#A2D3D8","#FFEFDE","#81996F"),
                    name="Outcomes")+
  labs(title="Confusion Metrics") +
  mapTheme

```


## 5.2 Predictions for Denver


**Prediction Defense**


* Our model has a high level of accuracy and generalizability.

* The predicted and observed values for Calgary line up well on the map.

* It accurately placed predicted inundation in Denver along the location of Denver's existing streams.


```{r predict_whole_denver, warning = FALSE, message= FALSE}

denver_dat_log <- denver_dat %>% 
  dplyr::select(uniqueID, pervious_mean, elevation_mean, flowac_mean_log, streamdist_min_log, geometry)

allPredictions_denver <- 
  predict(inundFit, denver_dat_log, type="prob")[,2]
  
denver_pred <- 
  cbind(denver_dat_log, allPredictions_denver) %>% 
  mutate(allPredictions_denver = round(allPredictions_denver * 100)) 



```

       
```{r predicted_map_denver, warning = FALSE, message = FALSE}


 ggplot() + 
     geom_sf(data=denver_pred, aes(fill=factor(ntile(allPredictions_denver,4))), 
            colour=NA) +
    scale_fill_manual(values = blues,
                      labels=as.character(quantile(denver_pred$allPredictions_denver,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Grouped in\nQuantile\nBreaks)") +
  mapTheme +
  labs(title="Predicted Probability of Flood Inundation in Denver",
        subtitle="Based on a Logistic Regression Model trained on data from Calgary\n")

  
```

``` {r pred map 2 denver, warning = FALSE, message = FALSE}

denver_hydro <- read_sf("Denver/Raw/streams/streams.shp")

  ggplot() + 
     geom_sf(data=denver_pred, aes(fill=factor(ntile(allPredictions_denver,4))), 
            colour=NA) +
    scale_fill_manual(values = blues,
                      labels=as.character(quantile(denver_pred$allPredictions_denver,
                                                 c(0.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Quantile\nBreaks)") +
   geom_sf(data=denver_hydro, color="#EDB025", size=35, linejoin="round", lineend="round") +
  labs(title="Predicted Probability of Flood Inundation in Denver",
        subtitle="Based on a Logistic Regression Model trained on data from Calgary\nYellow Lines Mark Location of Existing Rivers & Streams",
        caption = "Source: blah blah blah") +
   mapTheme


```

Phew, can't believe that worked...



# 6. Conclusion


**Next Steps**

Send to Denver municipal government with policy remommendations?


If we were to run through this project again we might:

* Find a way to integrate land porosity through run-off potential values.

* Incorporate some more variables from the stream network analysis, such as flow direction.
 



Thank you for watching :-)




xx

Charlie + Riddhi




## 6.1 Endnotes

1. City of Calgary. “Flooding in Calgary - Flood of 2013.” www.calgary.ca. Accessed March 27, 2023. https://www.calgary.ca/content/www/en/home/water/flooding/history-calgary.html.

2. “Flood Inundation Mapping (FIM) Program.” n.d. U.S. Geological Survey. Accessed February 27, 2023. https://www.usgs.gov/mission-areas/water-resources/science/flood-inundation-mapping-fim-program.

3. Hastie, T., Tibshirani, R., Friedman, J. 2009. The Elements of Statistical Learning: Data Mining, Interference, and Prediction. Second Ed. Available at: https://link.springer.com/book/10.1007/978-0-387-84858-7

