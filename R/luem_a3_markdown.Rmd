---
title: "CPLN 675_Assignment3"
author: "Riddhi Batra & Charlie Townsley"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
    code_folding: hide
    df_print: paged
    theme: flatly
    highlight: tango
---

# 1. Introduction

The purpose of this assignment is to...

...The Planning motivation for this algorithm and how we would deploy such an algorithm.


## 1.1 Setup


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#knitr::opts_knit$set(root.dir = "C:/Users/ctown/OneDrive - PennO365/Classes/Classes_Sem4_2023Spring/CPLN 675_Land Modeling/Assignments/LUEM_Assignment3_FloodInundationProbability/Data") #Charlie's directory

knitr::opts_knit$set(root.dir = "C:/Users/rids2/PennO365/Townsley, Charlie - LUEM_Assignment3_FloodInundationProbability/Data") #Riddhi's Directory

rm(list=ls())
```

```{r libraries, echo=FALSE}
library(tidyverse)
library(sf)
library(raster)
library(data.table)
library(ggcorrplot)
library(caret)
library(pscl)
library(plotROC)
library(pROC)
library(kableExtra)
library(tigris)
library(viridis)
```

```{r themes, warning = FALSE, message = FALSE, results = "hide"}

mapTheme <- theme(plot.title =element_text(size=12),
                  plot.subtitle = element_text(size=8),
                  plot.caption = element_text(size = 6),
                  axis.line=element_blank(),
                  axis.text.x=element_blank(),
                  axis.text.y=element_blank(),
                  axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank(),
                  panel.background=element_blank(),
                  panel.border=element_blank(),
                  panel.grid.major=element_line(colour = 'transparent'),
                  panel.grid.minor=element_blank(),
                  legend.direction = "vertical", 
                  legend.position = "right",
                  plot.margin = margin(1, 1, 1, 1, 'cm'),
                  legend.key.height = unit(1, "cm"), legend.key.width = unit(0.2, "cm"))

plotTheme <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.75),
  axis.ticks=element_blank())

#color nerds

blues <- c("#CEEBF0", "#A2D3D8", "#73B8BF", "#51A6AE", "#468D94", "#34696E")

greens <- c("#D8E5CE", "#C1D4B5", "#A9BF99", "#92AF7E", "#81996F", "#668053")

yellows <- c("#F9E2B2", "#EDC876", "#EDBA46", "#EDB025", "#AC832D", "#6E5321")

greys <- c("#ECEBF1", "#D3D3D9", "#B0B0B3", "#9C9C9E", "#7F7F80", "#656666")

neutrals <- c("#FDF4E9", "#FFEFDE", "#F6D7B2", "#D6B28B", "#A58565")

```

## 1.2 Load Data

```{r load_data, warning = FALSE, message = FALSE, results = "hide"}
denver_boundary <-read_sf("Denver/Processed/LUEM_Asgn3_Denver/NewData/denver_bound/denver_bound.shp")

calgary_boundary <- read_sf("Calgary/Raw/CALGIS_CITYBOUND_LIMIT/CALGIS_CITYBOUND_LIMIT.shp")
```


# 2. Fishnets and Data Wrangling


## 2.1 Create Fishnets

Create a fishnet for Calgary

```{r create_fishnets_calgary, warning = FALSE, message = FALSE, results = "hide"}

calgary_fishnet <- st_make_grid(calgary_boundary,
                        cellsize = 402.336,
                        square = FALSE) %>% 
  .[calgary_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = calgary_fishnet,
          fill = "lightgrey")+
  geom_sf(data = calgary_boundary, 
          color = "red", fill = "transparent")

#st_write(calgary_fishnet, "Calgary/Processed/calgary_fishnet/calgary_fishnet.shp", geometry = TRUE)

```


Create a fishnet for Denver

```{r create_fishnets_denver, warning = FALSE, message = FALSE, results = "hide"}

denver_fishnet <- st_make_grid(denver_boundary,
                        cellsize = 1320,
                        square = FALSE) %>% 
  .[denver_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = denver_fishnet,
          color="darkgrey", fill = "lightgrey")+
  geom_sf(data = denver_boundary, 
          color = "red", fill = "transparent")

#st_write(denver_fishnet, "Denver/Processed/R exports/denver_fishnet/denver_fishnet.shp", geometry = TRUE)
```

Create a fishnet for Calgary.
```{r create_fishnets_calgary, warning = FALSE, message = FALSE, results = "hide"}

calgary_fishnet <- st_make_grid(calgary_boundary,
                        cellsize = 402.336,
                        square = FALSE) %>% 
  .[calgary_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = calgary_fishnet,
          fill = "lightgrey")+
  geom_sf(data = calgary_boundary, 
          color = "red", fill = "transparent")

#st_write(calgary_fishnet, "Calgary/Processed/calgary_fishnet/calgary_fishnet.shp", geometry = TRUE)

```

## 2.2 Feature Engineering: Arc to R

Created features in ArcGIS to process and join in R. 

Join Calgary features to fishnet.

```{r join engineered features to calg fishnet, warning = FALSE, message = FALSE, results = "hide"}
#load in cleaned fishnet with partial cells removed
calgary_fishnet <-  read_sf("Calgary/Processed/calgary_fishnet_nozeros/calgary_fishnet_nozeros.shp")

#load in engineered features for calgary and process
calg_inund <- read_csv("Calgary/Processed/zonalstats_tables/calg_inundation_sum.csv") %>%
  rename(inund_sum = SUM) %>% 
  dplyr::select(uniqueID, inund_sum) %>% 
  mutate(inund_sum = ifelse(inund_sum >= 16, 1, 0)) #turn inundation sum values into binary (threshold = 16)

calg_pervious <- read.csv("Calgary/Processed/zonalstats_tables/calg_pervious_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(pervious_mean = MEAN)

calg_elevation <- read.csv("Calgary/Processed/zonalstats_tables/calg_elevation_med.csv") %>% 
    dplyr::select(uniqueID, MEDIAN) %>% 
  rename(elevation_median = MEDIAN)


calg_flowac <- read.csv("Calgary/Processed/zonalstats_tables/calg_flowac_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(flowac_mean = MEAN)


calg_streamdist <- read.csv("Calgary/Processed/zonalstats_tables/calg_dist2stream_min.csv") %>% 
    dplyr::select(uniqueID, MIN) %>% 
  rename(streamdist_min = MIN)

calg_dat <- calgary_fishnet %>%
  mutate(uniqueID = as.integer(uniqueID)) %>% 
  left_join(calg_inund, by = "uniqueID") %>% 
  left_join(calg_pervious, by = "uniqueID") %>%
  left_join(calg_elevation, by = "uniqueID") %>% 
  left_join(calg_flowac, by = "uniqueID") %>% 
  left_join(calg_streamdist, by = "uniqueID") %>% 
  mutate(flowac_mean_log = log(flowac_mean),
         streamdist_min_log = log(streamdist_min)) %>% 
  na.omit() %>% 
    dplyr::mutate(streamdist_min_log = if_else(streamdist_min_log <0, 0, streamdist_min_log),
         flowac_mean_log = if_else(flowac_mean_log <0, 0, flowac_mean_log))
  
```

Join Denver features to fishnet.

```{r get_variables_denver, warning = FALSE, message = FALSE, results = "hide"}

denv_pervious <- read.csv ("Denver/Processed/zonalstats_tables/denv_pervious_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(pervious_mean = MEAN)

denv_elevation <- read.csv("Denver/Processed/zonalstats_tables/denv_elevation_med.csv") %>% 
    dplyr::select(uniqueID, MEDIAN) %>% 
  rename(elevation_median = MEDIAN)


denv_flowac <- read.csv("Denver/Processed/zonalstats_tables/denv_flowac_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(flowac_mean = MEAN)


denv_streamdist <- read.csv("Denver/Processed/zonalstats_tables/denv_dist2stream_min.csv") %>% 
    dplyr::select(uniqueID, MIN) %>% 
  rename(streamdist_min = MIN)


denver_dat <- denver_fishnet %>%
  mutate(uniqueID = as.integer(uniqueID)) %>% 
  left_join(denv_pervious, by = 'uniqueID') %>%
  left_join(denv_elevation, by = 'uniqueID') %>% 
  left_join(denv_flowac, by = 'uniqueID') %>% 
  left_join(denv_streamdist, by = 'uniqueID') %>% 
    mutate(flowac_mean_log = log(flowac_mean),
         streamdist_min_log = log(streamdist_min)) %>% 
  na.omit() %>% 
    dplyr::mutate(streamdist_min_log = if_else(streamdist_min_log <0, 0, streamdist_min_log),
         flowac_mean_log = if_else(flowac_mean_log <0, 0, flowac_mean_log))
  
              
```


Set projections

```{r transform}
calg_dat <- calg_dat %>%
  st_transform(crs = 3776)

denver_dat <- denver_dat %>%
  st_transform(crs = 2232)
```


## 2.3 What is our Data Telling Us?


How do our variables correlate with inundated/not inundated values?

```{r wide_2_long}
calg_PlotVariables <- calg_dat %>% 
  as.data.frame() %>%
    dplyr::select(inund_sum, pervious_mean, elevation_median, flowac_mean_log, streamdist_min_log) %>% 
    pivot_longer(cols = -inund_sum)

```


``` {r data spread, warning = FALSE, message = FALSE, results = "hide"}

#violin plots
#change code for for calgary_dat
##use boxplots with scatter points to visualize the spread of data?

ggplot(calg_PlotVariables) + 
     geom_violin(aes(x = as.factor(inund_sum), 
                  y = value, fill = as.factor(inund_sum))) + 
     facet_wrap(~name, scales = "free_y") +
     labs(x="Inundated", y="Value") + 
     scale_fill_manual(values = c("#CEEBF0", "#51A6AE"),
     labels = c("Not Inundated","Inundated"), name = "") +
     labs(x="Inundated", y="Value") + 
  plotTheme

##facet_wrap - one ggplot recipe for each variable
###use scales = free or free_y to plot values that are comparatively lower or higher
```

``` {r correlation matrix, warning = FALSE, message = FALSE, results = "hide"}

corr <- calg_dat %>% 
  dplyr::select(inund_sum, pervious_mean, elevation_median, flowac_mean_log, streamdist_min_log) %>%  
  dplyr::summarise(inund_sum = (inund_sum),
            pervious_mean = (pervious_mean),
            elevation_median = (elevation_median),
            flowac_mean_log = (flowac_mean_log),
            streamdist_min_log = (streamdist_min_log))


calg_matrix = cor(corr)

ggcorrplot(calg_matrix, method="square", colors = c("gray2", "wheat1", "darkorchid4"),
           tl.cex=7)

```


How many fishnet cells in Calgary are inundated?

``` {r fishnet cell calcs, warning = FALSE, message = FALSE, results = "hide"}

#calculate on calgary_dat

calg_inund_fishnet <- calg_dat %>% 
  filter(inund_sum == 1)

no_fishnets <-(509/5373)*100

#About 509 of 5373, or 9.5% of fishnet cells in Calgary are inundated
```


# 3. Logistic Regressions

## 3.1 Test, Train, Repeat

```{r training_set, warning = FALSE, message = FALSE, results = "hide"}

#change code for calgary_dat

set.seed(3456)

trainIndex <- createDataPartition(calg_dat$elevation_median, p = .70,
                                  list = FALSE,
                                  times = 1) 

inundTrain <- calg_dat[ trainIndex,] %>% 
  dplyr::select(-flowac_mean, -streamdist_min)

inundTest  <- calg_dat[-trainIndex,]%>% 
  dplyr::select(-flowac_mean, -streamdist_min)

##the sets are randomly generated
##p=0.70 indicates the 70/30 partition
```


## 3.2 Regress

Now let’s estimate a logistic regression model. The binomial logit model runs in the `glm` function (generalized linear models). We specify the dependent variable as `preserve` and run the model on our training set `preserveTrain`.

Note how we can use the dplyr pipes right in the data parameter. We have to convert to a data frame because R won’t know how to run a regression on an sf.

Let's look at the model output, we see that we have coefficients, and p-values, but no R-squared. There are other goodness of fit metrics we will look at. The AIC, though not on a 0-1 scale like R-squared, has a similar function in that it tells you about overall model fit, but not about error and accuracy.

We are not really interested in our coefficients other than their magnitude, directionality and p-value (generall). But for the record, the way the coefficients in a logistic regression are interpreted is different than in OLS - we are talking in terms of "odds" of an outcome occurring (in our case odds of land being preserved.). If we exponentiate the coefficient (`exp()`) we can interpret it as *all else equal* the exponentiated value being the increase or decrease in the odds of the outcome.


```{r firstModel, warining = FALSE, message = FALSE}
inundModel <- glm(inund_sum ~ ., 
                    family="binomial"(link="logit"), data = inundTrain %>%
                                                            as.data.frame() %>%
                                                            dplyr::select(-geometry, -uniqueID))
summary(inundModel)

```


## 3.3 Model Validation

Using the `predict` function, we create a vector of classification probabilities we call `classProbs`. These are the predicted probability of a test set (`preserveTest`) fishnet cell being conserved conditional on our model. Setting the parameter `type="reponse"` returns probabilities that range from 0 to 1.


```{r predict_first}
classProbs <- predict(inundModel, inundTest, type="response")

hist(classProbs)

##histogram is for the whole dataset
##represents the probability that a cell will be inundated (x-axis), vs number of cells with that probability (y-axis)
```
The plot below illustrates a distribution of predicted probabilities, based on the training and test sets. It is a measure of how well our data is predicting probabilities for "inundation" (1s) vs "no inundation" (0s), where the vertical line represents a 0.5 probability of inundation.
In this case the values reflecting not inundated areas are clustered closer to zero, indicating a lower probability for inundation overall *(???)* 

```{r plot_preds}
testProbs <- data.frame(obs = as.numeric(inundTest$inund_sum),
                        pred = classProbs)

ggplot(testProbs, aes(x = pred, fill=as.factor(obs))) + 
  geom_density() +
  facet_grid(obs ~ .) + 
  xlab("Probability") + 
  ylab("Frequency") +
  geom_vline(xintercept = .5) +
  scale_fill_manual(values = c("#CEEBF0", "#51A6AE"),
                      labels = c("Not Inundated","Inundated"),
                      name = "")+
  plotTheme


```


# 4. Confusion, Indeed

## 4.1 Confusion Metrics

To test the model's prediction accuracy, we created a confusion matrix from which levels of error can be extrapolated.
If we assume a probability cutoff threshold of 50%, our confusion matrix gives us an accuracy of **0.923**, with the following sensitivity and specificity results:

**Sensitivity & Specificity Analysis**
_Predicted vs. Reference Values, 50% Cutoff_

-------------------
|   | 0    | 1    |
-------------------
| 0 | 1414 | 46   |
| 1 | 77   | 74   |
-------------------


* It has predicted 0 as 0, i.e. a _True Negative_, 1414 times
* It has predicted 0 as 1, i.e. a _False Negative_, 77 times
* It has predicted 1 as 0, i.e. a _False Positive_, 46 times
* It has predicted 1 as 1, i.e. a _True Positive_, 74 times

Overall, the model's true positive rate, i.e., the proportion of 1s predicted as 1s indicates its _sensitivity_, which in this case is almost twice as much as the number of 1s falsely predicted as 0s. The model's true negative rate, i.e., the proportion of 0s accurately predicted as 0s is about 18 times greater than the number of 0s falsely predicted as 1s, indicating the model's _specificity_.

It has an error rate of about 8% as derived from the accuracy (Error = Accuracy - 1), which is demonstrated by the fact that the model's 123 erroneous predictions (77+46) are only a small fraction of its 1488 accurate predictions (1414+74)

```{r confusion_matrix, message = FALSE, warning = FALSE}

testProbs$predClass  = ifelse(testProbs$pred > .5 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass), 
                       positive = "1")
```

We experimented with the threshold cutoff to check how the model would respond, and found that:

*The accuracy of a model with with a 75% threshold cutoff remains the same as the original model with a 50% cutoff. However, it contains slightly different levels of False Positive and False Negative predictions:


**Sensitivity & Specificity Analysis**
_Predicted vs. Reference Values, 75% Cutoff_

-------------------
|   | 0    | 1    |
-------------------
| 0 | 1454 | 118  |
| 1 | 6    | 33   |
-------------------


*Similarly, the accuracy of a model with a 25% cutoff is only marginally lower than the original model at 0.918, but it also exhibits a lower specificity:


**Sensitivity & Specificity Analysis**
_Predicted vs. Reference Values, 25% Cutoff_

-------------------
|   | 0    | 1    |
-------------------
| 0 | 1383 | 55   |
| 1 | 77   | 96   |
-------------------


```{r confusion_matrix_75_25, message = FALSE, warning = FALSE}

testProbs$predClass75  = ifelse(testProbs$pred > .75 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass75), 
                       positive = "1")

testProbs$predClass25  = ifelse(testProbs$pred > .25 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass25), 
                       positive = "1")

```


## 4.2 ROC Curve

The Receiver Operating Characteristic (ROC) curve for our original model with a 50% cutoff tells us that....

The area under the curve is calculated as 0.947, which confirms that the model is able to predict flood inundation with a 95% accuracy. 

See Appendix 1 for more on ROC curves.

```{r roc_curve, message = FALSE, warning = FALSE}

ggplot(testProbs, aes(d = obs, m = pred)) + 
  geom_roc(n.cuts = 50, labels = FALSE) + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') 
```

```{r auc, warning = FALSE}
auc(testProbs$obs, testProbs$pred)
```
## 4.3 Cross Validation for Generalizability

The following section checks the accuracy of our predictions across 100 randomly generated test sets, to gauge its applicability to predict Denver's chances of inundation.

Plotting a histogram of the accuracy for each fold allows us to trace its generalizability.
The plot points out that a large number of folds (i.e., values from the "Resample" column) are clustered at high accuracy values. 
This indicates a high level of generalizability -- a measure of the model's capacity to be applied to predict other sample sets -- in our case, flood inundation in Denver.

It gives the model confidence in moving to the final stage of the project -- applying Calgary's flood inundation predictions to the city of Denver. 


```{r k_fold, warning = FALSE, message = FALSE}

ctrl <- trainControl(method = "cv", 
                     number = 100, 
                     savePredictions = TRUE)

cvFit <- train(as.factor(inund_sum) ~ .,
               data = calg_dat %>% 
                 as.data.frame() %>%
                 dplyr::select(inund_sum, pervious_mean, elevation_median, flowac_mean_log, streamdist_min_log), 
               method="glm", family="binomial",
               trControl = ctrl)

cvFit

#cvFit is our model trained to predict using the binomial logistic regression, or glm, method. 
```

```{r cv_hist, warning = FALSE, message = FALSE}

ggplot(as.data.frame(cvFit$resample), aes(Accuracy)) + 
  geom_histogram() +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Accuracy",
       y="Count")+
  plotTheme
```

# 5. Map Predictions

Now that we have tuned our model, let’s predict for the entire dataset and assess our predictions.

```{r predict_whole, warning = FALSE, message= FALSE}

calg_dat_log <- calg_dat %>% 
  dplyr::select(uniqueID, inund_sum, pervious_mean, elevation_median, flowac_mean_log, streamdist_min_log, geometry) 

allPredictions <- 
  predict(cvFit, calg_dat_log, type="prob")[,2]
  
calg_pred <- 
  cbind(calg_dat_log,allPredictions) %>%
  mutate(allPredictions = round(allPredictions * 100)) 
```

Now we map the predictions.

What would you title this map? 

Note how we use ntile in the aes parameter to create quintiles. (The quintile labels are created in the scale_fill_manual function.)

```{r predicted_map1, warning = FALSE, message = FALSE}
 ggplot() + 
    geom_sf(data=calg_pred, aes(fill=factor(ntile(allPredictions,5))), 
            colour=NA) +
    scale_fill_manual(values = blues,
                      labels=as.character(quantile(calg_pred$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  mapTheme +
  labs(title="Predicted Probability of Flood Inundation in Calgary")
```

Let’s map it again with the already calculated inundation types overlaid.

```{r predicted_map2, warning = FALSE, message = FALSE}
 ggplot() + 
  geom_sf(data=calg_pred, aes(fill=factor(ntile(allPredictions,5))), colour=NA) +
  scale_fill_manual(values = blues,
                    labels=as.character(quantile(calg_pred$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                    name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  geom_sf(data=calg_pred  %>% 
               filter(inund_sum == 1), 
               fill="#EDBA46", alpha=0.9, colour=NA) +
    geom_sf(data=calg_pred %>% 
              filter(inund_sum == 0), 
            fill="#F9E2B2", alpha=0.35,colour=NA) +  
  mapTheme +
  labs(title="Observed and Predicted Flood Inundation Areas",
       subtitle="Yellow marks areas with observed 'inundation', all other taken as 'not inundated' for the purpose of binary regression modeling")
```

In spite of the confusion matrix indicating low levels of false negatives proportionate to the data we processed for Calgary, the map helps spatially visualize how the model's errors are spread out, and what might be contributing to them. 

There are a few reasons why the sensitivity and specificity indicators reflect the way they do in our model:

*When processing zonal statistics in ArcGIS, we chose to measure inundation as a sum of intersecting fishnet cells. When converting it to binary data, we chose a threshold of "Inundation Sum = 16" to reflect a higher possible level of inundation. This could be a contributing factor to the way False Negatives are attributed across Calgary's map -- 

*Our inundation data was extrapolated in ArcGIS from a raster layer where we subtracted the area of existing rivers, lakes, and streams from 'inundated' values, to more accurately reflect flood inundation external to water bodies. This could be reflecting a lack of observed .....



```{r error_map, warning = FALSE, message= FALSE}
calg_pred %>%
  mutate(confResult=case_when(allPredictions < 50 & inund_sum==0 ~ "True Negative",
                              allPredictions >= 50 & inund_sum==1 ~ "True Positive",
                              allPredictions < 50 & inund_sum==1 ~ "False Negative",
                              allPredictions >= 50 & inund_sum==0 ~ "False Positive")) %>%
  ggplot()+
  geom_sf(aes(fill = confResult), color = "transparent")+
  scale_fill_manual(values = c("Red","Orange","Light Blue","Light Green"),
                    name="Outcomes")+
  labs(title="Confusion Metrics") +
  mapTheme

```

*Does this type of model have more, less or the same level of usefulness as a raster-based site suitability? Why?*

## Predictions for Denver

```{r predict_whole_denver, warning = FALSE, message= FALSE}

denver_dat_log <- denver_dat %>% 
  dplyr::select(uniqueID, pervious_mean, elevation_median, flowac_mean_log, streamdist_min_log, geometry) 

allPredictions_denver <- 
  predict(cvFit, denver_dat_log, type="prob")[,2]
  
denver_pred <- 
  cbind(denver_dat_log,allPredictions_denver) %>%
  mutate(allPredictions = round(allPredictions_denver * 10000000)) 
```

```{r predicted_map_denver, warning = FALSE, message = FALSE}
 ggplot() + 
    geom_sf(data=denver_pred, aes(fill=factor(ntile(allPredictions,5))), 
            colour=NA) +
    scale_fill_manual(values = blues,
                      labels=as.character(quantile(denver_pred$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  mapTheme +
  labs(title="Predicted Probability of Flood Inundation in Denver",
       subtitle="Based on a Logistic Regression Model trained on data from Calgary")
```
