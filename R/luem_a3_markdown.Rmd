---
title: "CPLN 675_Assignment3"
author: "Riddhi Batra & Charlie Townsley"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
    code_folding: hide
    df_print: paged
    theme: flatly
    highlight: tango
---

# 1. Introduction

The purpose of this assignment is to...

...The Planning motivation for this algorithm and how we would deploy such an algorithm.


## 1.1 Setup


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_knit$set(root.dir = "C:/Users/ctown/OneDrive - PennO365/Classes/Classes_Sem4_2023Spring/CPLN 675_Land Modeling/Assignments/LUEM_Assignment3_FloodInundationProbability/Data") #Charlie's directory

#knitr::opts_knit$set(root.dir = "C:/Users/rids2/PennO365/Townsley, Charlie - LUEM_Assignment3_FloodInundationProbability/Data") #Riddhi's Directory

rm(list=ls())
```

```{r libraries, echo=FALSE}
library(tidyverse)
library(sf)
library(raster)
library(data.table)
```

```{r themes, warning = FALSE, message = FALSE, results = "hide"}

mapTheme <- theme(plot.title =element_text(size=12),
                  plot.subtitle = element_text(size=8),
                  plot.caption = element_text(size = 6),
                  axis.line=element_blank(),
                  axis.text.x=element_blank(),
                  axis.text.y=element_blank(),
                  axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank(),
                  panel.background=element_blank(),
                  panel.border=element_blank(),
                  panel.grid.major=element_line(colour = 'transparent'),
                  panel.grid.minor=element_blank(),
                  legend.direction = "vertical", 
                  legend.position = "right",
                  plot.margin = margin(1, 1, 1, 1, 'cm'),
                  legend.key.height = unit(1, "cm"), legend.key.width = unit(0.2, "cm"))

plotTheme <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.75),
  axis.ticks=element_blank())

#color nerds

blues <- c("#CEEBF0", "#A2D3D8", "#73B8BF", "#51A6AE", "#468D94", "#34696E")

greens <- c("#D8E5CE", "#C1D4B5", "#A9BF99", "#92AF7E", "#81996F", "#668053")

yellows <- c("#F9E2B2", "#EDC876", "#EDBA46", "#EDB025", "#AC832D", "#6E5321")

greys <- c("#ECEBF1", "#D3D3D9", "#B0B0B3", "#9C9C9E", "#7F7F80", "#656666")

neutrals <- c("#FDF4E9", "#FFEFDE", "#F6D7B2", "#D6B28B", "#A58565")

```

## 1.2 Load Data

```{r load_data, warning = FALSE, message = FALSE, results = "hide"}
denver_boundary <-read_sf("Denver/Processed/LUEM_Asgn3_Denver/NewData/denver_bound/denver_bound.shp")

calgary_boundary <- read_sf("Calgary/Raw/CALGIS_CITYBOUND_LIMIT/CALGIS_CITYBOUND_LIMIT.shp")
```


# 2. Fishnets and Data Wrangling


## 2.1 Create Fishnets


Create a fishnet for Calgary to do processing in ArcGIS.

```{r create_fishnets_calgary, warning = FALSE, message = FALSE, results = "hide"}

calgary_fishnet <- st_make_grid(calgary_boundary,
                        cellsize = 402.336,
                        square = FALSE) %>% 
  .[calgary_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = calgary_fishnet,
          fill = "lightgrey")+
  geom_sf(data = calgary_boundary, 
          color = "red", fill = "transparent") +
  mapTheme

st_write(calgary_fishnet, "Calgary/Processed/calgary_fishnet/calgary_fishnet.shp", geometry = TRUE)

```


Create a fishnet for Denver to do processing in ArcGIS.

```{r create_fishnets_denver, warning = FALSE, message = FALSE, results = "hide"}

denver_fishnet <- st_make_grid(denver_boundary,
                        cellsize = 1320,
                        square = FALSE) %>% 
  .[denver_boundary] %>% 
  st_sf() %>% 
  mutate(uniqueID = rownames(.))

ggplot()+
  geom_sf(data = denver_fishnet,
          color="darkgrey", fill = "lightgrey") +
  geom_sf(data = denver_boundary, 
          color = "red", fill = "transparent") +
  mapTheme
  

#st_write(denver_fishnet, "Denver/Processed/R exports/denver_fishnet/denver_fishnet.shp", geometry = TRUE)
```


## 2.2 Feature Engineering: Arc to R

Processed raster features for Calgary are exported from ArcGIS as tables containing zonal statistics by fishnet cell. These tables are then re-imported to R and joined with their respective fishnets. The list of features in question is:
* Flood inundation
* Pervious and impervious landcover
* Elevation
* Flow accumulation
* Distance to river

```{r join engineered features to calg fishnet, warning = FALSE, message = FALSE, results = "hide"}
#load in cleaned fishnet with partial cells removed
calgary_fishnet <-  read_sf("Calgary/Processed/calgary_fishnet_nozeros/calgary_fishnet_nozeros.shp")

#load in engineered features for calgary and process
calg_inund <- read_csv("Calgary/Processed/zonalstats_tables/calg_inundation_sum.csv") %>%
  rename(inund_sum = SUM) %>% 
  dplyr::select(uniqueID, inund_sum) %>% 
  mutate(inund_sum = ifelse(inund_sum >= 16, 1, 0)) #turn inundation sum values into binary (threshold = 16)

calg_pervious <- read.csv("Calgary/Processed/zonalstats_tables/calg_pervious_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(pervious_mean = MEAN)

calg_elevation <- read.csv("Calgary/Processed/zonalstats_tables/calg_elevation_med.csv") %>% 
    dplyr::select(uniqueID, MEDIAN) %>% 
  rename(elevation_median = MEDIAN)


calg_flowac <- read.csv("Calgary/Processed/zonalstats_tables/calg_flowac_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(flowac_mean = MEAN)


calg_streamdist <- read.csv("Calgary/Processed/zonalstats_tables/calg_dist2stream_min.csv") %>% 
    dplyr::select(uniqueID, MIN) %>% 
  rename(streamdist_min = MIN)

calg_dat <- calgary_fishnet %>%
  mutate(uniqueID = as.integer(uniqueID)) %>% 
  left_join(calg_inund, by = 'uniqueID') %>% 
  left_join(calg_pervious, by = 'uniqueID') %>%
  left_join(calg_elevation, by = 'uniqueID') %>% 
  left_join(calg_flowac, by = 'uniqueID') %>% 
  left_join(calg_streamdist, by = 'uniqueID') %>% 
  mutate(flowac_mean_log = log(flowac_mean),
         streamdist_min_log = log(streamdist_min)) %>% 
  na.omit()
  
```


The same process is followed for Denver with the same features, excluding inundation.

```{r get_variables_denver, warning = FALSE, message = FALSE, results = "hide"}

denv_pervious <- read.csv ("Denver/Processed/zonalstats_tables/denv_pervious_mean.csv") %>% 
  dplyr::select(uniqueID, MEAN) %>% 
  rename(pervious_mean = MEAN)

denv_elevation <- read.csv("Denver/Processed/zonalstats_tables/denv_elevation_med.csv") %>% 
    dplyr::select(uniqueID, MEDIAN) %>% 
  rename(elevation_median = MEDIAN)


denv_flowac <- read.csv("Denver/Processed/zonalstats_tables/denv_flowac_mean.csv") %>% 
    dplyr::select(uniqueID, MEAN) %>% 
  rename(flowac_mean = MEAN)


denv_streamdist <- read.csv("Denver/Processed/zonalstats_tables/denv_dist2stream_min.csv") %>% 
    dplyr::select(uniqueID, MIN) %>% 
  rename(streamdist_min = MIN)


denver_dat <- denver_fishnet %>%
  mutate(uniqueID = as.integer(uniqueID)) %>% 
  left_join(denv_pervious, by = 'uniqueID') %>%
  left_join(denv_elevation, by = 'uniqueID') %>% 
  left_join(denv_flowac, by = 'uniqueID') %>% 
  left_join(denv_streamdist, by = 'uniqueID')
              
```


## 2.3 Mapping Features

Mapping the fishnet of calgary with these features reveals...

```{r mapping calgary inundation}
calg_dat <- calg_dat %>%
  st_transform(crs = 3776)

ggplot() +
  geom_sf(data = calgary_boundary, aes(fill="#FFEFDE", color = "#656666"))+
  geom_sf(data=calg_dat, aes(fill=as.factor(inund_sum)), alpha = 0.8, color = "#D3D3D9") +
  scale_fill_manual(values = c("#FFEFDE", "#34696E"),
                    labels = c("Not Inundated", "Inundated"), name = "") +
  labs(title="Flood Inundation in Calgary") +
  mapTheme

```


```{r mapping denver }
denver_dat <- denver_dat %>%
  st_transform(crs = 2232)

```



## 2.4 What is our Data Telling Us?


How do our variables correlate with inundated/not inundated values?

```{r wide_2_long}
inundPlotVariables <- calg_dat %>% 
  as.data.frame() %>%
    dplyr::select(inund_sum, pervious_mean, elevation_median, flowac_mean_log, streamdist_min_log) %>% 
    pivot_longer(cols = -inund_sum)
```


``` {r data spread, warning = FALSE, message = FALSE, results = "hide"}

#violin plots
#change code for for calgary_dat
##use boxplots with scatter points to visualize the spread of data?

ggplot(inundPlotVariables) + 
     geom_violin(aes(x = as.factor(inund_sum), 
                  y = value, fill = as.factor(inund_sum))) + 
     facet_wrap(~name, scales = "free_y") +
     labs(x="Inundated", y="Value") + 
     scale_fill_manual(values = c("#CEEBF0", "#51A6AE"),
     labels = c("Not Inundated","Inundated"), name = "") +
     labs(x="Inundated", y="Value") + 
  plotTheme

##facet_wrap - one ggplot recipe for each variable
###use scales = free or free_y to plot values that are comparatively lower or higher
```

``` {r: correlation matrix, warning = FALSE, message = FALSE, results = "hide"}

#Riddhi to get code for this

```


How many fishnet cells in Calgary are inundated?

``` {r: fishnet cell calcs, warning = FALSE, message = FALSE, results = "hide"}

#calculate on calgary_dat



```


# 3. Logistic Regressions

## 3.1 Test, Train, Repeat

```{r training_set, warning = FALSE, message = FALSE, results = "hide"}

#change code for calgary_dat

set.seed(3456)
trainIndex <- createDataPartition(preserve$landCover, p = .70,
                                  list = FALSE,
                                  times = 1)

preserveTrain <- preserve[ trainIndex,]
preserveTest  <- preserve[-trainIndex,]

##the sets are randomly generated
##p=0.70 indicates the 70/30 partition
```


## 3.2 Regress

Now let’s estimate a logistic regression model. The binomial logit model runs in the `glm` function (generalized linear models). We specify the dependent variable as `preserve` and run the model on our training set `preserveTrain`.

Note how we can use the dplyr pipes right in the data parameter. We have to convert to a data frame because R won’t know how to run a regression on an sf.

Let's look at the model output, we see that we have coefficients, and p-values, but no R-squared. There are other goodness of fit metrics we will look at. The AIC, though not on a 0-1 scale like R-squared, has a similar function in that it tells you about overall model fit, but not about error and accuracy.

We are not really interested in our coefficients other than their magnitude, directionality and p-value (generall). But for the record, the way the coefficients in a logistic regression are interpreted is different than in OLS - we are talking in terms of "odds" of an outcome occurring (in our case odds of land being preserved.). If we exponentiate the coefficient (`exp()`) we can interpret it as *all else equal* the exponentiated value being the increase or decrease in the odds of the outcome.


```{r firstModel, warining = FALSE, message = FALSE}
preserveModel <- glm(preserve ~ ., 
                    family="binomial"(link="logit"), data = preserveTrain %>%
                                                            as.data.frame() %>%
                                                            select(-geometry, -Id))
summary(preserveModel)

```


## 3.3 Model Validation

Using the `predict` function, we create a vector of classification probabilities we call `classProbs`. These are the predicted probability of a test set (`preserveTest`) fishnet cell being conserved conditional on our model. Setting the parameter `type="reponse"` returns probabilities that range from 0 to 1.


```{r predict_first}
classProbs <- predict(preserveModel, preserveTest, type="response")

hist(classProbs)

##histogram is for the whole dataset
##represents the probability that a cell will be preserved (x-axis), vs number of cells with that probability (y-axis)
```

Let’s put `classProbs` into a data frame along with the observed `preserve` outcome, which is either `1` for preserved land or `0` for unpreserved.

Then we build this funky plot, `testProbsPlot`. The vertical line represents a 0.5 probability of preservation.

__Can you interperet this plot? Can you come up with a title for this plot?__

```{r plot_preds}
testProbs <- data.frame(obs = as.numeric(preserveTest$preserve),
                        pred = classProbs)

ggplot(testProbs, aes(x = pred, fill=as.factor(obs))) + 
  geom_density() +
  facet_grid(obs ~ .) + 
  xlab("Probability") + 
  ylab("Frequency") +
  geom_vline(xintercept = .5) +
  scale_fill_manual(values = c("dark blue", "dark green"),
                      labels = c("Not Preserved","Preserved"),
                      name = "")+
  plotTheme

##y-axis are unit-less values
```


# 4. Confusion, Indeed

## 4.1 Confusion Metrics

__Now we have to figure out at which probability level do we wish to classify land as being preserved.  How do we make this decision?__

Let’s (arbitrarily for now) choose 50% and then create a table of our correct and incorrect predictions, called a "confusion matrix". Below we set the reference to the observed preserved status, data to the predicted outcome, and make sure to state which factor level is the positive (ie. preserved) level. Note that `confusionMatrix` does not take numeric inputs, only factors.

```{r confusion_matrix, message = FALSE, warning = FALSE}
testProbs$predClass  = ifelse(testProbs$pred > .5 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass), 
                       positive = "1")
```

What is the sensitivity and specificity suggest about our model? What is accuracy suggest? Why would we choose a higher threshold cutoff?

**Predicted = 0, Observed = 0 —> True Negative**

**Predicted = 1, Observed = 1 —> True Positive**

**Predicted = 1, Observed = 0 —> False Positive**

**Predicted = 0, Observed = 1 —> False Negative**

**1. Sensitivity - the proportion of actual positives (1’s) that were predicted to be positive. Also known as “true positive rate”.**

**2. Specificity - The proportion of actual negatives (0’s) that were predicted to be negatives. Also known as “true negative rate”.**

## 4.2 ROC Curve

Let's create an ROC (receiver operating characteristic) curve. What does this tell us? 

See Appendix 1 for more on ROC curves.

```{r roc_curve, message = FALSE, warning = FALSE}

ggplot(testProbs, aes(d = obs, m = pred)) + 
  geom_roc(n.cuts = 50, labels = FALSE) + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') 
```

How about the area under the curve?

```{r auc, warning = FALSE}
auc(testProbs$obs, testProbs$pred)
```


## 4.3 Cross Validation


